{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files[0] => tweets_#gohawks.txt\n",
      "files[1] => tweets_#gopatriots.txt\n",
      "files[2] => tweets_#nfl.txt\n",
      "files[3] => tweets_#patriots.txt\n",
      "files[4] => tweets_#sb49.txt\n",
      "files[5] => tweets_#superbowl.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "path = \"../tweet_data/\"\n",
    "\n",
    "files = [\"tweets_#gohawks.txt\", \"tweets_#gopatriots.txt\", \\\n",
    "        \"tweets_#nfl.txt\", \"tweets_#patriots.txt\", \\\n",
    "        \"tweets_#sb49.txt\", \"tweets_#superbowl.txt\"]\n",
    "\n",
    "for i, fl in enumerate(files):\n",
    "    print \"files[\" + str(i) + \"] => \" + fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the 2015 Feb. 1, 8:00 am and 8:00 pm into timestamp form\n",
    "import datetime, time\n",
    "import pytz\n",
    "\n",
    "start_time = time.mktime(time.strptime(\"2015-02-01 08:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "end_time = time.mktime(time.strptime(\"2015-02-01 20:00:00\",'%Y-%m-%d %H:%M:%S'))\n",
    "# used as the zero point of the time\n",
    "base_time = time.mktime(time.strptime(\"2015-01-01 00:00:00\",'%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floor_date(date):\n",
    "    return date // 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the extracted data contains\n",
    "# 0. the citation date 1. the favourite_count 2. the followers number\n",
    "# 3. the length of the title 4. the number of the twitters\n",
    "def load_file(file):\n",
    "    '''\n",
    "    load the time, follows, and retweets\n",
    "    '''\n",
    "    # 0. before Feb. 1, 8:00 a.m. 1. between 2. after 8:00 p.m.\n",
    "    result = [[], [], []]\n",
    "    for line in open(path + file, 'r') :\n",
    "        tmp = []\n",
    "        a = json.loads(line)\n",
    "        citation_date = a['citation_date']\n",
    "        tmp.append(int((citation_date - base_time) // 3600))\n",
    "        tmp.append(a['author']['followers'])\n",
    "        tmp.append(a['tweet']['user']['favourites_count'])\n",
    "        tmp.append(len(a['title']))\n",
    "        tmp.append(1)\n",
    "        if citation_date < start_time:\n",
    "            result[0].append(tmp)\n",
    "        elif citation_date < end_time:\n",
    "            result[1].append(tmp)\n",
    "        else:\n",
    "            result[2].append(tmp)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gohawks = load_file(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[394, 1752.0, 9490, 52, 1]\n"
     ]
    }
   ],
   "source": [
    "print gohawks[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data(dataset):\n",
    "    '''\n",
    "    parameter dataset is one of the three time slot defined above, namely, data[0], data[1], data[2]\n",
    "    count all the features in 1-hour slot\n",
    "    \n",
    "    return the train feature (train_set[0:4]) and the result (train_set[5])\n",
    "    '''\n",
    "    # get the maximum and minimum time\n",
    "    max_time = dataset[0][0]\n",
    "    min_time = dataset[0][0]\n",
    "    for p in dataset:\n",
    "        time = p[0]\n",
    "        if max_time < time:\n",
    "            max_time = time\n",
    "        if min_time > time:\n",
    "            min_time = time\n",
    "    \n",
    "    train_set = []\n",
    "    \n",
    "    for i in range(min_time, max_time + 1):\n",
    "        train_set.append([0] * 5)\n",
    "    \n",
    "    for p in dataset:\n",
    "        index = p[0] - min_time\n",
    "        train_set[index][0] = p[0]\n",
    "        for i in range(1, 5):\n",
    "            train_set[index][i] += p[i]\n",
    "    \n",
    "    result = []\n",
    "    for i in range(0, max_time - min_time):\n",
    "        result.append(train_set[i + 1][4])\n",
    "    \n",
    "    return train_set[:-1], result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = group_data(gohawks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(predict, target):\n",
    "    '''\n",
    "        used to get the average error between predict and target\n",
    "    '''\n",
    "    length = len(target)\n",
    "    return sum([abs(predict[i] - target[i]) for i in range(length)]) / float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using k-fold to divide the train and test set \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits = n_splits, shuffle = True)\n",
    "\n",
    "def k_fold(X, y, train_model):\n",
    "    '''\n",
    "        use k-fold to split the data and use train_model to train and predict\n",
    "        return the average error of the model\n",
    "    '''\n",
    "    error = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_feature = []\n",
    "        test_feature = []\n",
    "        train_result = []\n",
    "        test_result = []\n",
    "        for index in train_index:\n",
    "            train_feature.append(X[index])\n",
    "            train_result.append(y[index])\n",
    "        for index in test_index:\n",
    "            test_feature.append(X[index])\n",
    "            test_result.append(y[index])\n",
    "            \n",
    "        model = train_model.fit(train_feature, train_result)\n",
    "        predict = model.predict(test_feature)\n",
    "        error += get_error(predict, test_result)\n",
    "    return error / n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "clf = MLPRegressor(alpha = 0.001, hidden_layer_sizes = (500,), \\\n",
    "                           activation = 'tanh', verbose = 'True', learning_rate = 'adaptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "time_range = {0: \"Before Feb. 1, 8:00 a.m. \", 1: \"Between Feb. 1, 8:00 a.m. and 8:00 p.m. \", \\\n",
    "              2: \"After Feb. 1, 8:00 p.m.\"}\n",
    "final_result = []\n",
    "for f in files:\n",
    "    file_data = load_file(f)\n",
    "    for i in range(3):\n",
    "        X, y = group_data(file_data[i])\n",
    "        a = \"the file is \" + f + \" , the time range is \" + time_range[i] + \\\n",
    "        \" and the error is \" + str(k_fold(X, y, lr)) + \\\n",
    "        \" and \" + str(k_fold(X, y, clf))\n",
    "        final_result.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the file is tweets_#gohawks.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 298.78617575083246 and 229.96939577973026', 'the file is tweets_#gohawks.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 5954.150163060607 and 5598.004875977421', 'the file is tweets_#gohawks.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 24.45815507934528 and 37.66107208859721', 'the file is tweets_#gopatriots.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 14.079448973180286 and 14.157146051560655', 'the file is tweets_#gopatriots.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 871.3723275871664 and 1474.0190328947078', 'the file is tweets_#gopatriots.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 3.6269646255435632 and 3.462097063680017', 'the file is tweets_#nfl.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 125.22197523254142 and 189.1319905124039', 'the file is tweets_#nfl.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 2806.9336588673837 and 4547.429549959975', 'the file is tweets_#nfl.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 110.1479411306974 and 467.43603062344994', 'the file is tweets_#patriots.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 225.243401625635 and 288.17226912825413', 'the file is tweets_#patriots.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 23841.728732132546 and 27447.832125791745', 'the file is tweets_#patriots.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 92.06801004472311 and 149.37042753917135', 'the file is tweets_#sb49.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 35.883797786477885 and 94.14157283925036', 'the file is tweets_#sb49.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 70698.19664333863 and 67170.60817353181', 'the file is tweets_#sb49.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 184.97371989934928 and 361.4007095013261', 'the file is tweets_#superbowl.txt , the time range is Before Feb. 1, 8:00 a.m.  and the error is 251.37212154880427 and 411.2148671800752', 'the file is tweets_#superbowl.txt , the time range is Between Feb. 1, 8:00 a.m. and 8:00 p.m.  and the error is 132566.31205740076 and 86923.74194175811', 'the file is tweets_#superbowl.txt , the time range is After Feb. 1, 8:00 p.m. and the error is 181.43186375783895 and 706.6246120278788']\n"
     ]
    }
   ],
   "source": [
    "print final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.02162181459596\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "print k_fold(X, y, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "clf = MLPRegressor(alpha = 0.001, hidden_layer_sizes = (500,), \\\n",
    "                           activation = 'tanh', verbose = 'True', learning_rate = 'adaptive')\n",
    "x = k_fold(X, y, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.57008211494954"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
